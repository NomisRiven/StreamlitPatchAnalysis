{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Winrates - League of Legends\n",
    "## Comparaison entre Patches\n",
    "\n",
    "Ce notebook permet d'analyser les variations de winrate des champions entre deux patches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pandas lxml openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úì Imports r√©ussis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "**MODIFIE ICI LES PATCHES √Ä COMPARER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs et headers\n",
    "BASE_URL = \"https://lolalytics.com/lol\"\n",
    "LANES = [\"top\", \"jungle\", \"middle\", \"bottom\", \"support\"]\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "}\n",
    "\n",
    "# ========== CONFIGURATION DU SCRAPING ==========\n",
    "TIER = \"diamond_plus\"  # master_plus, diamond_plus, platinum_plus, etc.\n",
    "REGION = \"all\"  # all, euw, na, kr, etc.\n",
    "PATCH_1 = \"15.24\"  # Premier patch (ancien)\n",
    "PATCH_2 = \"16.1\"   # Second patch (nouveau)\n",
    "# ================================================\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Tier: {TIER}\")\n",
    "print(f\"  Region: {REGION}\")\n",
    "print(f\"  Patches √† comparer: {PATCH_1} vs {PATCH_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Liste des champions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAMPIONS = [\n",
    "    \"aatrox\", \"ahri\", \"akali\", \"akshan\", \"alistar\", \"ambessa\", \"amumu\", \"anivia\", \"annie\", \"aphelios\",\n",
    "    \"mel\", \"ashe\", \"aurelionsol\", \"aurora\", \"azir\", \"bard\", \"belveth\", \"blitzcrank\", \"brand\", \"braum\", \"briar\",\n",
    "    \"caitlyn\", \"camille\", \"cassiopeia\", \"chogath\", \"corki\", \"darius\", \"diana\", \"draven\", \"drmundo\",\n",
    "    \"ekko\", \"elise\", \"evelynn\", \"ezreal\", \"fiddlesticks\", \"fiora\", \"fizz\", \"galio\", \"gangplank\",\n",
    "    \"garen\", \"gnar\", \"gragas\", \"graves\", \"gwen\", \"hecarim\", \"heimerdinger\", \"hwei\", \"illaoi\", \"irelia\",\n",
    "    \"ivern\", \"janna\", \"jarvaniv\", \"jax\", \"jayce\", \"jhin\", \"jinx\", \"kaisa\", \"kalista\", \"karma\",\n",
    "    \"karthus\", \"kassadin\", \"katarina\", \"kayle\", \"kayn\", \"kennen\", \"khazix\", \"kindred\", \"kled\",\n",
    "    \"kogmaw\", \"ksante\", \"leblanc\", \"leesin\", \"leona\", \"lillia\", \"lissandra\", \"lucian\", \"lulu\", \"lux\",\n",
    "    \"malphite\", \"malzahar\", \"maokai\", \"masteryi\", \"milio\", \"missfortune\", \"mordekaiser\", \"morgana\",\n",
    "    \"naafiri\", \"nami\", \"nasus\", \"nautilus\", \"neeko\", \"nidalee\", \"nilah\", \"nocturne\", \"nunu\", \"olaf\",\n",
    "    \"orianna\", \"ornn\", \"pantheon\", \"poppy\", \"pyke\", \"qiyana\", \"quinn\", \"rakan\", \"rammus\", \"reksai\",\n",
    "    \"rell\", \"renata\", \"renekton\", \"rengar\", \"riven\", \"rumble\", \"ryze\", \"samira\", \"sejuani\", \"senna\",\n",
    "    \"seraphine\", \"sett\", \"shaco\", \"shen\", \"shyvana\", \"singed\", \"sion\", \"sivir\", \"skarner\", \"smolder\",\n",
    "    \"sona\", \"soraka\", \"swain\", \"sylas\", \"syndra\", \"tahmkench\", \"taliyah\", \"talon\", \"taric\", \"teemo\",\n",
    "    \"thresh\", \"tristana\", \"trundle\", \"tryndamere\", \"twistedfate\", \"twitch\", \"udyr\", \"urgot\", \"varus\",\n",
    "    \"vayne\", \"veigar\", \"velkoz\", \"vex\", \"vi\", \"viego\", \"viktor\", \"vladimir\", \"volibear\", \"warwick\",\n",
    "    \"wukong\", \"xayah\", \"xerath\", \"xinzhao\", \"yasuo\", \"yone\", \"yorick\", \"yuumi\", \"zac\", \"zed\", \"zeri\",\n",
    "    \"ziggs\", \"zilean\", \"zoe\", \"zyra\"\n",
    "]\n",
    "\n",
    "print(f\"‚úì {len(CHAMPIONS)} champions configur√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Fonctions de scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url: str, params: Optional[Dict] = None) -> Optional[str]:\n",
    "    \"\"\"R√©cup√®re le HTML d'une page\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_qwik_json(html: str) -> Optional[Dict]:\n",
    "    \"\"\"Extrait les donn√©es JSON de la page\"\"\"\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    qwik_script = soup.find('script', type='qwik/json')\n",
    "    if not qwik_script or not qwik_script.string:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(qwik_script.string)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def decode_ref(ref_str: str, objs: List) -> any:\n",
    "    \"\"\"D√©code les r√©f√©rences dans le JSON\"\"\"\n",
    "    if isinstance(ref_str, str):\n",
    "        try:\n",
    "            idx = int(ref_str, 36)\n",
    "            if 0 <= idx < len(objs):\n",
    "                return objs[idx]\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return ref_str\n",
    "\n",
    "\n",
    "def find_champion_stats(objs: List) -> Optional[Dict]:\n",
    "    \"\"\"Trouve les statistiques du champion dans les donn√©es JSON\"\"\"\n",
    "    for obj in objs:\n",
    "        if isinstance(obj, dict):\n",
    "            required_keys = {'wr', 'pr', 'br', 'n', 'avgWr'}\n",
    "            if required_keys.issubset(set(obj.keys())):\n",
    "                stats = {}\n",
    "                for key in ['wr', 'avgWr', 'avgWrDelta', 'pr', 'br', 'n', 'tier']:\n",
    "                    if key in obj:\n",
    "                        stats[key] = decode_ref(obj[key], objs)\n",
    "                return stats\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_champion_stats(champion: str, lane: str, tier: str, region: str, patch: str) -> Optional[Dict]:\n",
    "    \"\"\"R√©cup√®re les statistiques d'un champion pour une lane et un patch donn√©s\"\"\"\n",
    "    url = f\"{BASE_URL}/{champion}/build/\"\n",
    "    params = {\"tier\": tier, \"region\": region, \"patch\": patch, \"lane\": lane}\n",
    "\n",
    "    html = get_html(url, params)\n",
    "    if not html:\n",
    "        return None\n",
    "\n",
    "    qwik_data = extract_qwik_json(html)\n",
    "    if not qwik_data or 'objs' not in qwik_data:\n",
    "        return None\n",
    "\n",
    "    champion_stats = find_champion_stats(qwik_data['objs'])\n",
    "    if champion_stats:\n",
    "        return {\n",
    "            'champion': champion,\n",
    "            'lane': lane,\n",
    "            'patch': patch,\n",
    "            'winrate': champion_stats.get('wr'),\n",
    "            'pickrate': champion_stats.get('pr'),\n",
    "            'banrate': champion_stats.get('br'),\n",
    "            'games': champion_stats.get('n'),\n",
    "            'tier': champion_stats.get('tier')\n",
    "        }\n",
    "    return None\n",
    "\n",
    "\n",
    "def scrape_all_champions_patch(patch: str, tier: str, region: str) -> pd.DataFrame:\n",
    "    \"\"\"Scrape tous les champions pour un patch donn√©\"\"\"\n",
    "    all_data = []\n",
    "    total = len(CHAMPIONS) * len(LANES)\n",
    "    current = 0\n",
    "\n",
    "    print(f\"Scraping patch {patch}...\")\n",
    "    \n",
    "    for champion in CHAMPIONS:\n",
    "        for lane in LANES:\n",
    "            current += 1\n",
    "            stats = get_champion_stats(champion, lane, tier, region, patch)\n",
    "            \n",
    "            if stats:\n",
    "                all_data.append(stats)\n",
    "                if current % 50 == 0:\n",
    "                    print(f\"  [{current}/{total}] En cours...\")\n",
    "            \n",
    "            time.sleep(0.15)\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(f\"‚úì Patch {patch}: {len(df)} lignes r√©cup√©r√©es\")\n",
    "    return df\n",
    "\n",
    "print(\"‚úì Fonctions de scraping d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Scraping des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp de fetch\n",
    "fetch_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f\"üìÖ D√©but du scraping: {fetch_timestamp}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Scraping Patch 1\n",
    "print(f\"\\nSCRAPING PATCH {PATCH_1}\")\n",
    "print(\"=\" * 70)\n",
    "df_patch_1 = scrape_all_champions_patch(PATCH_1, TIER, REGION)\n",
    "df_patch_1['fetch_timestamp'] = fetch_timestamp\n",
    "\n",
    "print(f\"\\nüìä Aper√ßu Patch {PATCH_1}:\")\n",
    "display(df_patch_1.head(10))\n",
    "\n",
    "# Scraping Patch 2\n",
    "print(f\"\\n\\nSCRAPING PATCH {PATCH_2}\")\n",
    "print(\"=\" * 70)\n",
    "df_patch_2 = scrape_all_champions_patch(PATCH_2, TIER, REGION)\n",
    "df_patch_2['fetch_timestamp'] = fetch_timestamp\n",
    "\n",
    "print(f\"\\nüìä Aper√ßu Patch {PATCH_2}:\")\n",
    "display(df_patch_2.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Cr√©ation du DataFrame de comparaison\n",
    "\n",
    "Structure finale:\n",
    "```\n",
    "champion, lane, \n",
    "patch_X, winrate_X, pickrate_X, banrate_X, games_X, tier_X,\n",
    "patch_Y, winrate_Y, pickrate_Y, banrate_Y, games_Y, tier_Y,\n",
    "wr_change, pr_change, br_change\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer les colonnes pour avoir la structure demand√©e\n",
    "df_p1 = df_patch_1.copy()\n",
    "df_p2 = df_patch_2.copy()\n",
    "\n",
    "# Sauvegarder le timestamp avant de le supprimer temporairement\n",
    "timestamp_value = df_p1['fetch_timestamp'].iloc[0]\n",
    "\n",
    "# Supprimer fetch_timestamp temporairement pour le merge\n",
    "df_p1 = df_p1.drop('fetch_timestamp', axis=1)\n",
    "df_p2 = df_p2.drop('fetch_timestamp', axis=1)\n",
    "\n",
    "# Renommer avec les noms de patches dynamiques\n",
    "df_p1 = df_p1.rename(columns={\n",
    "    'patch': f'patch_{PATCH_1}',\n",
    "    'winrate': f'winrate_{PATCH_1}',\n",
    "    'pickrate': f'pickrate_{PATCH_1}',\n",
    "    'banrate': f'banrate_{PATCH_1}',\n",
    "    'games': f'games_{PATCH_1}',\n",
    "    'tier': f'tier_{PATCH_1}'\n",
    "})\n",
    "\n",
    "df_p2 = df_p2.rename(columns={\n",
    "    'patch': f'patch_{PATCH_2}',\n",
    "    'winrate': f'winrate_{PATCH_2}',\n",
    "    'pickrate': f'pickrate_{PATCH_2}',\n",
    "    'banrate': f'banrate_{PATCH_2}',\n",
    "    'games': f'games_{PATCH_2}',\n",
    "    'tier': f'tier_{PATCH_2}'\n",
    "})\n",
    "\n",
    "# Merge sur champion et lane\n",
    "comparison = df_p1.merge(df_p2, on=['champion', 'lane'])\n",
    "\n",
    "# Calculer les changements\n",
    "comparison['wr_change'] = comparison[f'winrate_{PATCH_2}'] - comparison[f'winrate_{PATCH_1}']\n",
    "comparison['pr_change'] = comparison[f'pickrate_{PATCH_2}'] - comparison[f'pickrate_{PATCH_1}']\n",
    "comparison['br_change'] = comparison[f'banrate_{PATCH_2}'] - comparison[f'banrate_{PATCH_1}']\n",
    "\n",
    "# Ajouter le timestamp\n",
    "comparison['fetch_timestamp'] = timestamp_value\n",
    "\n",
    "# R√©organiser les colonnes dans l'ordre demand√©\n",
    "column_order = [\n",
    "    'champion', 'lane',\n",
    "    f'patch_{PATCH_1}', f'winrate_{PATCH_1}', f'pickrate_{PATCH_1}', f'banrate_{PATCH_1}', f'games_{PATCH_1}', f'tier_{PATCH_1}',\n",
    "    f'patch_{PATCH_2}', f'winrate_{PATCH_2}', f'pickrate_{PATCH_2}', f'banrate_{PATCH_2}', f'games_{PATCH_2}', f'tier_{PATCH_2}',\n",
    "    'wr_change', 'pr_change', 'br_change',\n",
    "    'fetch_timestamp'\n",
    "]\n",
    "\n",
    "comparison = comparison[column_order]\n",
    "\n",
    "# Trier par plus gros changement de winrate\n",
    "comparison_sorted = comparison.sort_values('wr_change', ascending=False)\n",
    "\n",
    "print(f\"‚úì DataFrame de comparaison cr√©√©: {len(comparison)} champion-lane combinations\\n\")\n",
    "print(f\"üìä Structure du DataFrame:\")\n",
    "print(comparison_sorted.columns.tolist())\n",
    "print(f\"\\nüîù Top 10 buffs:\")\n",
    "display(comparison_sorted[['champion', 'lane', f'winrate_{PATCH_1}', f'winrate_{PATCH_2}', 'wr_change']].head(10))\n",
    "print(f\"\\nüîª Top 10 nerfs:\")\n",
    "display(comparison_sorted[['champion', 'lane', f'winrate_{PATCH_1}', f'winrate_{PATCH_2}', 'wr_change']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Sauvegarde des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un timestamp pour les noms de fichiers (sans caract√®res invalides)\n",
    "file_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "df_patch_1.to_csv(f'patch_{PATCH_1}_{TIER}_{file_timestamp}.csv', index=False)\n",
    "df_patch_2.to_csv(f'patch_{PATCH_2}_{TIER}_{file_timestamp}.csv', index=False)\n",
    "comparison_sorted.to_csv(f'comparison_{PATCH_1}_vs_{PATCH_2}_{TIER}_{file_timestamp}.csv', index=False)\n",
    "\n",
    "print(f\"‚úì Fichiers CSV sauvegard√©s:\")\n",
    "print(f\"  - patch_{PATCH_1}_{TIER}_{file_timestamp}.csv ({len(df_patch_1)} lignes)\")\n",
    "print(f\"  - patch_{PATCH_2}_{TIER}_{file_timestamp}.csv ({len(df_patch_2)} lignes)\")\n",
    "print(f\"  - comparison_{PATCH_1}_vs_{PATCH_2}_{TIER}_{file_timestamp}.csv ({len(comparison_sorted)} lignes)\")\n",
    "\n",
    "# Sauvegarder en Excel avec plusieurs feuilles\n",
    "with pd.ExcelWriter(f'champion_analysis_{PATCH_1}_vs_{PATCH_2}_{TIER}_{file_timestamp}.xlsx', engine='openpyxl') as writer:\n",
    "    df_patch_1.to_excel(writer, sheet_name=f'Patch {PATCH_1}', index=False)\n",
    "    df_patch_2.to_excel(writer, sheet_name=f'Patch {PATCH_2}', index=False)\n",
    "    comparison_sorted.to_excel(writer, sheet_name='Comparison', index=False)\n",
    "\n",
    "print(f\"\\n‚úì Fichier Excel sauvegard√©: champion_analysis_{PATCH_1}_vs_{PATCH_2}_{TIER}_{file_timestamp}.xlsx\")\n",
    "print(f\"\\nüìÖ Donn√©es r√©cup√©r√©es le: {fetch_timestamp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
